{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "detector_backends = [ 'opencv', 'retinaface',\n",
    "        'mtcnn', 'ssd', 'dlib', 'mediapipe', 'yolov8', 'centerface'] # or 'skip' (default is opencv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faces Detection\n",
    "faces=DeepFace.extract_faces(img_path=\"img.jpg\", #select the image [it can have multiple faces]\n",
    "                             detector_backend = 'mtcnn', #[select the backend among mtcnn, opencv, ssd, dlib]\n",
    "                             enforce_detection = False, #pass this argument to disable multiple face detection\n",
    "                             align = True, #pass this argument to align faces\n",
    "                             margin = 10) #add margin for face extraction\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c46a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Facial Recognition\n",
    "models = [\n",
    "  \"VGG-Face\", \n",
    "  \"Facenet\", \n",
    "  \"Facenet512\", \n",
    "  \"OpenFace\", \n",
    "  \"DeepFace\", \n",
    "  \"DeepID\", \n",
    "  \"ArcFace\", \n",
    "  \"Dlib\", \n",
    "  \"SFace\",\n",
    "  \"GhostFaceNet\",\n",
    "]\n",
    "#You can adjust the threshold according to your use case. Print the result and see the distance values. Then, you can decide the optimal threshold for your project.\n",
    "#you can use any of the these models for verify and find methods for recognition\n",
    "fr_result = DeepFace.verify(\n",
    "  img1_path = \"img1.jpg\",\n",
    "  img2_path = \"img2.jpg\",\n",
    ")\n",
    "print(fr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deepface's find method\n",
    "dfs = DeepFace.find(\n",
    "  img_path = \"img1.jpg\",\n",
    "  db_path = \"PATH_TO_YOUR_DB\"\n",
    ")\n",
    "print(dfs) #you can print the result to see the distance values\n",
    "\n",
    "#Facial Analysis\n",
    "objs = DeepFace.analyze(\n",
    "  img_path = \"img1.jpg\", \n",
    "  actions = ['age', 'gender', 'race', 'emotion'],\n",
    ")\n",
    "print(objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab050cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Facial Embeddings\n",
    "embedding_objs = DeepFace.represent(\n",
    "  img_path = \"img1.jpg\",\n",
    "  model_name = models[2],\n",
    ")\n",
    "#These can be used for clustering, finding similarity between faces, vector operations, by storing in a vector database for faster retrieval, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
